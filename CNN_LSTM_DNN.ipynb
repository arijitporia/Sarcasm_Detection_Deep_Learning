{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_LSTM_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIw4XXSqwEdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKSC02jEwf8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK1Etqb-wkvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z]+\"\n",
        "DATASET_ENCODING = \"ISO-8859-1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wg5s6alwlnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMaAEp-UwsNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/sarcastic_comments_train.csv',index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6hjI7l7F9d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abbr={\"ain't\": \"is not\", \"isn't\": 'is not',\"cannot\": \"can not\", \"aren't\": \"are not\", \"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
        "                \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\",\n",
        "                \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
        "                \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
        "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n",
        "                \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\", \"they'd\": \"they would\",\n",
        "                \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
        "                \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\",\n",
        "                \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"wont\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "                \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
        "                \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color',\n",
        "                'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor',\n",
        "                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', '2F4U':\t'Too Fast For You',\n",
        "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I',\n",
        "                'theBest': 'the best', 'howdoes': 'how does', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what',\n",
        "                'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'AKA':\t'also known as', 'ACK':\t'Acknowledgment', 'AFAIK':\t'As far as I know', 'AFAIR':\t'As far as I remember'}\n",
        "\n",
        "abbr = {k.lower(): v.lower() for k, v in abbr.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yMmgx9LO23b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_word(word):\n",
        "    temp = word\n",
        "    while True:\n",
        "        w = re.sub(r\"([a-zA-Z])\\1\\1\", r\"\\1\\1\", temp)\n",
        "        if (w == temp):\n",
        "            break\n",
        "        else:\n",
        "            temp = w\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwPEBZESVJpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text,abbreviation_dict=abbr, stem=False):\n",
        "    # Remove link,user and special characters\n",
        "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
        "\n",
        "    filtered_text=[]\n",
        "    for t in text.split(' '):\n",
        "        if (t in abbreviation_dict):\n",
        "            tok = abbreviation_dict.get(t).split(' ')\n",
        "            filtered_text.extend(tok)\n",
        "        else:\n",
        "            filtered_text.append(t)\n",
        "\n",
        "    tokee=[normalize_word(word) for word in filtered_text]\n",
        "\n",
        "    tokens = []\n",
        "    for token in tokee:\n",
        "        if stem:\n",
        "            tokens.append(stemmer.stem(token))\n",
        "        else:\n",
        "            tokens.append(token)\n",
        "    ll=['b','c','d','e','f','g','h','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "    tokens=[g for g in tokens if g not in ll]\n",
        "    if len(tokens)>=1:\n",
        "        return \" \".join(tokens)\n",
        "    else:\n",
        "        return float('NaN')\n",
        "df.comment = df.comment.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS_xBkzyw2jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.dropna(axis=0,how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RLZcUNLp6cQ",
        "colab_type": "code",
        "outputId": "9a065fdc-4c59-48bc-ccf4-ec15fa667b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df.comment)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words 109443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVfsWULrqIGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pad_sequences(tokenizer.texts_to_sequences(df.comment), maxlen=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aIz0w9AseCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=df.label\n",
        "y=np.array(y)\n",
        "y = y.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLZgl13Xqjq_",
        "colab_type": "code",
        "outputId": "386e80ec-fb75-4b3d-d5d0-298bcf6c0cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/My Drive/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCkGMOkFrxuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjS7ITB7sic0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Activation, BatchNormalization, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1DnASh4sRXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=400, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzGvMPGxsy7L",
        "colab_type": "code",
        "outputId": "51c93d1e-b072-48b3-9e73-45b1fa9abd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "### MODEL-1 ###\n",
        "model = Sequential()\n",
        "model.add(e)\n",
        "model.add(Conv1D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='sigmoid', padding='valid',input_shape=(1,400)))\n",
        "#model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='sigmoid', padding='valid'))\n",
        "#model.add(MaxPooling1D(pool_size=2))\n",
        "#model.add(LSTM(128, kernel_initializer='he_normal', activation='sigmoid', dropout=0.25, return_sequences=True))\n",
        "model.add(LSTM(256, kernel_initializer='he_normal', activation='sigmoid', dropout=0.25))\n",
        "model.add(Dense(128, kernel_initializer='he_normal', activation='sigmoid'))\n",
        "model.add(Dense(64, kernel_initializer='he_normal', activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 300)          32832900  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 398, 64)           57664     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 396, 128)          24704     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 33,350,725\n",
            "Trainable params: 517,825\n",
            "Non-trainable params: 32,832,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqh1YjorEF-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### MODEL-2 ###\n",
        "model = Sequential()\n",
        "model.add(e)\n",
        "model.add(Conv1D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='sigmoid', padding='valid',input_shape=(1,400)))\n",
        "#model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='sigmoid', padding='valid'))\n",
        "#model.add(MaxPooling1D(pool_size=2))\n",
        "#model.add(Bidirectional(LSTM(128, kernel_initializer='he_normal', activation='sigmoid', dropout=0.25, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(256, kernel_initializer='he_normal', activation='sigmoid',dropout=0.25)))\n",
        "model.add(Dense(128, kernel_initializer='he_normal', activation='sigmoid'))\n",
        "model.add(Dense(64, kernel_initializer='he_normal', activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NutCOsAyLJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp8RNoxD6H7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLOT MODEL\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_layer_names=False,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiUXkgY02mdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4KY_wfsyOhD",
        "colab_type": "code",
        "outputId": "d1cab611-c896-4b78-9a1f-456fd8a4bad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "history = model.fit(X,y, batch_size=1024, epochs=20, validation_split=0.1,verbose=1, callbacks=[es])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "405/405 [==============================] - 309s 764ms/step - loss: 0.6785 - accuracy: 0.5617 - val_loss: 0.6515 - val_accuracy: 0.6188\n",
            "Epoch 2/20\n",
            "405/405 [==============================] - 307s 759ms/step - loss: 0.6408 - accuracy: 0.6313 - val_loss: 0.6364 - val_accuracy: 0.6309\n",
            "Epoch 3/20\n",
            "405/405 [==============================] - 304s 751ms/step - loss: 0.6248 - accuracy: 0.6469 - val_loss: 0.6218 - val_accuracy: 0.6489\n",
            "Epoch 4/20\n",
            "405/405 [==============================] - 306s 757ms/step - loss: 0.6120 - accuracy: 0.6593 - val_loss: 0.6018 - val_accuracy: 0.6691\n",
            "Epoch 5/20\n",
            "405/405 [==============================] - 310s 765ms/step - loss: 0.5965 - accuracy: 0.6748 - val_loss: 0.5846 - val_accuracy: 0.6855\n",
            "Epoch 6/20\n",
            "405/405 [==============================] - 312s 771ms/step - loss: 0.5826 - accuracy: 0.6879 - val_loss: 0.5756 - val_accuracy: 0.6944\n",
            "Epoch 7/20\n",
            "405/405 [==============================] - 313s 773ms/step - loss: 0.5735 - accuracy: 0.6962 - val_loss: 0.5687 - val_accuracy: 0.6988\n",
            "Epoch 8/20\n",
            "405/405 [==============================] - 312s 770ms/step - loss: 0.5648 - accuracy: 0.7035 - val_loss: 0.5615 - val_accuracy: 0.7047\n",
            "Epoch 9/20\n",
            "405/405 [==============================] - 316s 780ms/step - loss: 0.5591 - accuracy: 0.7078 - val_loss: 0.5767 - val_accuracy: 0.6904\n",
            "Epoch 10/20\n",
            "405/405 [==============================] - 316s 781ms/step - loss: 0.5538 - accuracy: 0.7122 - val_loss: 0.5639 - val_accuracy: 0.7009\n",
            "Epoch 11/20\n",
            "405/405 [==============================] - 320s 789ms/step - loss: 0.5498 - accuracy: 0.7149 - val_loss: 0.5516 - val_accuracy: 0.7149\n",
            "Epoch 12/20\n",
            "405/405 [==============================] - 321s 794ms/step - loss: 0.5448 - accuracy: 0.7200 - val_loss: 0.5470 - val_accuracy: 0.7174\n",
            "Epoch 13/20\n",
            "405/405 [==============================] - 312s 770ms/step - loss: 0.5418 - accuracy: 0.7215 - val_loss: 0.5465 - val_accuracy: 0.7174\n",
            "Epoch 14/20\n",
            "405/405 [==============================] - 312s 770ms/step - loss: 0.5384 - accuracy: 0.7249 - val_loss: 0.5452 - val_accuracy: 0.7182\n",
            "Epoch 15/20\n",
            "405/405 [==============================] - 305s 752ms/step - loss: 0.5358 - accuracy: 0.7269 - val_loss: 0.5423 - val_accuracy: 0.7226\n",
            "Epoch 16/20\n",
            "405/405 [==============================] - 304s 751ms/step - loss: 0.5321 - accuracy: 0.7296 - val_loss: 0.5451 - val_accuracy: 0.7185\n",
            "Epoch 17/20\n",
            "405/405 [==============================] - 307s 757ms/step - loss: 0.5296 - accuracy: 0.7312 - val_loss: 0.5415 - val_accuracy: 0.7223\n",
            "Epoch 18/20\n",
            "405/405 [==============================] - 308s 761ms/step - loss: 0.5268 - accuracy: 0.7335 - val_loss: 0.5454 - val_accuracy: 0.7202\n",
            "Epoch 19/20\n",
            "405/405 [==============================] - 307s 757ms/step - loss: 0.5244 - accuracy: 0.7354 - val_loss: 0.5445 - val_accuracy: 0.7204\n",
            "Epoch 20/20\n",
            "405/405 [==============================] - 307s 758ms/step - loss: 0.5222 - accuracy: 0.7374 - val_loss: 0.5411 - val_accuracy: 0.7226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYGh5IChDYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/CNNLSTM_train.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqB9M6LdhOo_",
        "colab_type": "code",
        "outputId": "0c4967d0-cdfb-4a02-dd57-c4e4dc756633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/My Drive/CNNLSTM_train.h5')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sMWQ9Mr27Bp",
        "colab_type": "code",
        "outputId": "a26f0f70-ef12-49c7-aeb7-b8030b3cbc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Reecgv2vUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/My Drive/sarcastic_comments_test.csv',index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41dHv5w121oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.comment = df1.comment.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQP-Zk8p265h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=df1.dropna(axis=0,how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCN_up8f3GfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = pad_sequences(tokenizer.texts_to_sequences(df1.comment), maxlen=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDXEvWJQ4gKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1=df1.label\n",
        "y1=np.array(y1)\n",
        "y1 = y1.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi3_QmuK4UNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "801cf87c-1cc2-4a33-d3c9-2240a9bed2db"
      },
      "source": [
        "model.evaluate(X1,y1)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3599/3599 [==============================] - 150s 42ms/step - loss: 0.5398 - accuracy: 0.7232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5398172736167908, 0.7231910228729248]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APTbqfqtR8NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "new_input = model.input\n",
        "hidden_layer = model.layers[-2].output\n",
        "\n",
        "features_extract_model = tensorflow.keras.Model(new_input, hidden_layer)\n",
        "features_extract_model.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stf65LVzR9s3",
        "colab_type": "code",
        "outputId": "e1483755-b47d-4322-99c2-04e4f1d06f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaW26nMISBaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I=[i for i in range(0,X.shape[0],1000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z622B3XASF3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I.append(X.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PePKUqmUSZRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NDF=pd.DataFrame(columns=[str(t) for t in range(64)])\n",
        "for i in range(len(I[0:-1])):\n",
        "    x=tf.convert_to_tensor(X[I[i]:I[i+1]])\n",
        "    z=features_extract_model(x)\n",
        "    ndf=pd.DataFrame(z.numpy(),columns=[str(t) for t in range(64)])\n",
        "    lst = [NDF, ndf]\n",
        "    NDF = pd.concat(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm0Zc8AB6iYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "6a6f393b-3c86-48b2-a4f6-23b21e0e59e5"
      },
      "source": [
        "NDF"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.231430</td>\n",
              "      <td>0.352931</td>\n",
              "      <td>0.232025</td>\n",
              "      <td>0.606499</td>\n",
              "      <td>0.549468</td>\n",
              "      <td>0.539599</td>\n",
              "      <td>0.437592</td>\n",
              "      <td>0.323234</td>\n",
              "      <td>0.650981</td>\n",
              "      <td>0.648691</td>\n",
              "      <td>0.451481</td>\n",
              "      <td>0.189666</td>\n",
              "      <td>0.413894</td>\n",
              "      <td>0.752051</td>\n",
              "      <td>0.509668</td>\n",
              "      <td>0.407237</td>\n",
              "      <td>0.140910</td>\n",
              "      <td>0.742027</td>\n",
              "      <td>0.146832</td>\n",
              "      <td>0.448269</td>\n",
              "      <td>0.674707</td>\n",
              "      <td>0.301753</td>\n",
              "      <td>0.550699</td>\n",
              "      <td>0.249950</td>\n",
              "      <td>0.300689</td>\n",
              "      <td>0.349405</td>\n",
              "      <td>0.169064</td>\n",
              "      <td>0.111726</td>\n",
              "      <td>0.271988</td>\n",
              "      <td>0.544923</td>\n",
              "      <td>0.466076</td>\n",
              "      <td>0.263267</td>\n",
              "      <td>0.262848</td>\n",
              "      <td>0.316530</td>\n",
              "      <td>0.602520</td>\n",
              "      <td>0.531608</td>\n",
              "      <td>0.201113</td>\n",
              "      <td>0.188011</td>\n",
              "      <td>0.145850</td>\n",
              "      <td>0.385094</td>\n",
              "      <td>0.314296</td>\n",
              "      <td>0.444696</td>\n",
              "      <td>0.223954</td>\n",
              "      <td>0.743735</td>\n",
              "      <td>0.830242</td>\n",
              "      <td>0.281772</td>\n",
              "      <td>0.815895</td>\n",
              "      <td>0.393487</td>\n",
              "      <td>0.628838</td>\n",
              "      <td>0.428363</td>\n",
              "      <td>0.690105</td>\n",
              "      <td>0.456538</td>\n",
              "      <td>0.272487</td>\n",
              "      <td>0.639819</td>\n",
              "      <td>0.184266</td>\n",
              "      <td>0.514249</td>\n",
              "      <td>0.430497</td>\n",
              "      <td>0.682713</td>\n",
              "      <td>0.538324</td>\n",
              "      <td>0.620999</td>\n",
              "      <td>0.415200</td>\n",
              "      <td>0.153995</td>\n",
              "      <td>0.469210</td>\n",
              "      <td>0.563165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.285400</td>\n",
              "      <td>0.280855</td>\n",
              "      <td>0.309056</td>\n",
              "      <td>0.690448</td>\n",
              "      <td>0.629205</td>\n",
              "      <td>0.632035</td>\n",
              "      <td>0.509149</td>\n",
              "      <td>0.413318</td>\n",
              "      <td>0.733105</td>\n",
              "      <td>0.725586</td>\n",
              "      <td>0.530865</td>\n",
              "      <td>0.135359</td>\n",
              "      <td>0.337519</td>\n",
              "      <td>0.804715</td>\n",
              "      <td>0.590082</td>\n",
              "      <td>0.506966</td>\n",
              "      <td>0.101012</td>\n",
              "      <td>0.801865</td>\n",
              "      <td>0.170794</td>\n",
              "      <td>0.509009</td>\n",
              "      <td>0.592571</td>\n",
              "      <td>0.354594</td>\n",
              "      <td>0.651956</td>\n",
              "      <td>0.311090</td>\n",
              "      <td>0.382311</td>\n",
              "      <td>0.289675</td>\n",
              "      <td>0.230790</td>\n",
              "      <td>0.163489</td>\n",
              "      <td>0.359548</td>\n",
              "      <td>0.443361</td>\n",
              "      <td>0.522579</td>\n",
              "      <td>0.201728</td>\n",
              "      <td>0.195044</td>\n",
              "      <td>0.232233</td>\n",
              "      <td>0.496986</td>\n",
              "      <td>0.455459</td>\n",
              "      <td>0.144521</td>\n",
              "      <td>0.122659</td>\n",
              "      <td>0.181734</td>\n",
              "      <td>0.312899</td>\n",
              "      <td>0.240488</td>\n",
              "      <td>0.518400</td>\n",
              "      <td>0.173341</td>\n",
              "      <td>0.667426</td>\n",
              "      <td>0.883685</td>\n",
              "      <td>0.357278</td>\n",
              "      <td>0.871824</td>\n",
              "      <td>0.330535</td>\n",
              "      <td>0.716373</td>\n",
              "      <td>0.517706</td>\n",
              "      <td>0.740414</td>\n",
              "      <td>0.377812</td>\n",
              "      <td>0.336039</td>\n",
              "      <td>0.558734</td>\n",
              "      <td>0.131916</td>\n",
              "      <td>0.600984</td>\n",
              "      <td>0.344973</td>\n",
              "      <td>0.778269</td>\n",
              "      <td>0.605696</td>\n",
              "      <td>0.681855</td>\n",
              "      <td>0.339217</td>\n",
              "      <td>0.105349</td>\n",
              "      <td>0.391168</td>\n",
              "      <td>0.490527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.259602</td>\n",
              "      <td>0.315595</td>\n",
              "      <td>0.275291</td>\n",
              "      <td>0.652674</td>\n",
              "      <td>0.591544</td>\n",
              "      <td>0.589445</td>\n",
              "      <td>0.474199</td>\n",
              "      <td>0.372337</td>\n",
              "      <td>0.698281</td>\n",
              "      <td>0.690780</td>\n",
              "      <td>0.489585</td>\n",
              "      <td>0.160169</td>\n",
              "      <td>0.371900</td>\n",
              "      <td>0.779884</td>\n",
              "      <td>0.554924</td>\n",
              "      <td>0.462727</td>\n",
              "      <td>0.120253</td>\n",
              "      <td>0.773628</td>\n",
              "      <td>0.158722</td>\n",
              "      <td>0.478898</td>\n",
              "      <td>0.625067</td>\n",
              "      <td>0.329089</td>\n",
              "      <td>0.608256</td>\n",
              "      <td>0.281386</td>\n",
              "      <td>0.342607</td>\n",
              "      <td>0.316674</td>\n",
              "      <td>0.204076</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>0.321293</td>\n",
              "      <td>0.490418</td>\n",
              "      <td>0.493556</td>\n",
              "      <td>0.227510</td>\n",
              "      <td>0.225033</td>\n",
              "      <td>0.268570</td>\n",
              "      <td>0.541100</td>\n",
              "      <td>0.490187</td>\n",
              "      <td>0.171045</td>\n",
              "      <td>0.150243</td>\n",
              "      <td>0.167259</td>\n",
              "      <td>0.346213</td>\n",
              "      <td>0.272983</td>\n",
              "      <td>0.482918</td>\n",
              "      <td>0.193889</td>\n",
              "      <td>0.701710</td>\n",
              "      <td>0.859236</td>\n",
              "      <td>0.321756</td>\n",
              "      <td>0.847256</td>\n",
              "      <td>0.359304</td>\n",
              "      <td>0.677596</td>\n",
              "      <td>0.478099</td>\n",
              "      <td>0.716047</td>\n",
              "      <td>0.414957</td>\n",
              "      <td>0.306571</td>\n",
              "      <td>0.593226</td>\n",
              "      <td>0.157291</td>\n",
              "      <td>0.565091</td>\n",
              "      <td>0.381068</td>\n",
              "      <td>0.737766</td>\n",
              "      <td>0.574830</td>\n",
              "      <td>0.658285</td>\n",
              "      <td>0.374811</td>\n",
              "      <td>0.127841</td>\n",
              "      <td>0.427011</td>\n",
              "      <td>0.523648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135609</td>\n",
              "      <td>0.568508</td>\n",
              "      <td>0.123433</td>\n",
              "      <td>0.385045</td>\n",
              "      <td>0.354287</td>\n",
              "      <td>0.333921</td>\n",
              "      <td>0.264728</td>\n",
              "      <td>0.171629</td>\n",
              "      <td>0.417465</td>\n",
              "      <td>0.410441</td>\n",
              "      <td>0.270935</td>\n",
              "      <td>0.395903</td>\n",
              "      <td>0.621124</td>\n",
              "      <td>0.558305</td>\n",
              "      <td>0.316164</td>\n",
              "      <td>0.228673</td>\n",
              "      <td>0.341952</td>\n",
              "      <td>0.526354</td>\n",
              "      <td>0.086212</td>\n",
              "      <td>0.267503</td>\n",
              "      <td>0.811338</td>\n",
              "      <td>0.174238</td>\n",
              "      <td>0.331260</td>\n",
              "      <td>0.139753</td>\n",
              "      <td>0.160514</td>\n",
              "      <td>0.546920</td>\n",
              "      <td>0.085860</td>\n",
              "      <td>0.043297</td>\n",
              "      <td>0.139913</td>\n",
              "      <td>0.746310</td>\n",
              "      <td>0.304265</td>\n",
              "      <td>0.470444</td>\n",
              "      <td>0.488822</td>\n",
              "      <td>0.540826</td>\n",
              "      <td>0.781340</td>\n",
              "      <td>0.705282</td>\n",
              "      <td>0.419118</td>\n",
              "      <td>0.421010</td>\n",
              "      <td>0.082157</td>\n",
              "      <td>0.583726</td>\n",
              "      <td>0.536257</td>\n",
              "      <td>0.261738</td>\n",
              "      <td>0.414428</td>\n",
              "      <td>0.858338</td>\n",
              "      <td>0.595354</td>\n",
              "      <td>0.146342</td>\n",
              "      <td>0.589362</td>\n",
              "      <td>0.553585</td>\n",
              "      <td>0.400259</td>\n",
              "      <td>0.254974</td>\n",
              "      <td>0.508863</td>\n",
              "      <td>0.652017</td>\n",
              "      <td>0.143387</td>\n",
              "      <td>0.786650</td>\n",
              "      <td>0.402635</td>\n",
              "      <td>0.325770</td>\n",
              "      <td>0.625559</td>\n",
              "      <td>0.418562</td>\n",
              "      <td>0.351140</td>\n",
              "      <td>0.449257</td>\n",
              "      <td>0.610430</td>\n",
              "      <td>0.376007</td>\n",
              "      <td>0.665616</td>\n",
              "      <td>0.731804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.256028</td>\n",
              "      <td>0.319747</td>\n",
              "      <td>0.262084</td>\n",
              "      <td>0.642367</td>\n",
              "      <td>0.581280</td>\n",
              "      <td>0.578273</td>\n",
              "      <td>0.467271</td>\n",
              "      <td>0.359131</td>\n",
              "      <td>0.688087</td>\n",
              "      <td>0.682831</td>\n",
              "      <td>0.485078</td>\n",
              "      <td>0.165043</td>\n",
              "      <td>0.381432</td>\n",
              "      <td>0.775816</td>\n",
              "      <td>0.548619</td>\n",
              "      <td>0.450037</td>\n",
              "      <td>0.121396</td>\n",
              "      <td>0.771875</td>\n",
              "      <td>0.157717</td>\n",
              "      <td>0.475822</td>\n",
              "      <td>0.635517</td>\n",
              "      <td>0.324885</td>\n",
              "      <td>0.597387</td>\n",
              "      <td>0.272469</td>\n",
              "      <td>0.334392</td>\n",
              "      <td>0.323226</td>\n",
              "      <td>0.193437</td>\n",
              "      <td>0.131853</td>\n",
              "      <td>0.308530</td>\n",
              "      <td>0.504324</td>\n",
              "      <td>0.491608</td>\n",
              "      <td>0.232600</td>\n",
              "      <td>0.232021</td>\n",
              "      <td>0.275320</td>\n",
              "      <td>0.556638</td>\n",
              "      <td>0.496099</td>\n",
              "      <td>0.174881</td>\n",
              "      <td>0.157857</td>\n",
              "      <td>0.160451</td>\n",
              "      <td>0.351499</td>\n",
              "      <td>0.282653</td>\n",
              "      <td>0.477444</td>\n",
              "      <td>0.199256</td>\n",
              "      <td>0.713251</td>\n",
              "      <td>0.855982</td>\n",
              "      <td>0.311365</td>\n",
              "      <td>0.842654</td>\n",
              "      <td>0.362880</td>\n",
              "      <td>0.670880</td>\n",
              "      <td>0.466050</td>\n",
              "      <td>0.713529</td>\n",
              "      <td>0.418632</td>\n",
              "      <td>0.299761</td>\n",
              "      <td>0.605897</td>\n",
              "      <td>0.159954</td>\n",
              "      <td>0.552626</td>\n",
              "      <td>0.390857</td>\n",
              "      <td>0.725773</td>\n",
              "      <td>0.571346</td>\n",
              "      <td>0.649042</td>\n",
              "      <td>0.383497</td>\n",
              "      <td>0.131711</td>\n",
              "      <td>0.437430</td>\n",
              "      <td>0.526776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>0.216491</td>\n",
              "      <td>0.381766</td>\n",
              "      <td>0.210946</td>\n",
              "      <td>0.573881</td>\n",
              "      <td>0.520956</td>\n",
              "      <td>0.505727</td>\n",
              "      <td>0.414888</td>\n",
              "      <td>0.288955</td>\n",
              "      <td>0.616031</td>\n",
              "      <td>0.616030</td>\n",
              "      <td>0.417708</td>\n",
              "      <td>0.213789</td>\n",
              "      <td>0.442223</td>\n",
              "      <td>0.733526</td>\n",
              "      <td>0.485206</td>\n",
              "      <td>0.374849</td>\n",
              "      <td>0.157154</td>\n",
              "      <td>0.723365</td>\n",
              "      <td>0.143045</td>\n",
              "      <td>0.427868</td>\n",
              "      <td>0.693611</td>\n",
              "      <td>0.282220</td>\n",
              "      <td>0.520477</td>\n",
              "      <td>0.227889</td>\n",
              "      <td>0.276235</td>\n",
              "      <td>0.375570</td>\n",
              "      <td>0.149515</td>\n",
              "      <td>0.096336</td>\n",
              "      <td>0.248454</td>\n",
              "      <td>0.587121</td>\n",
              "      <td>0.456744</td>\n",
              "      <td>0.283188</td>\n",
              "      <td>0.290044</td>\n",
              "      <td>0.342084</td>\n",
              "      <td>0.635390</td>\n",
              "      <td>0.549405</td>\n",
              "      <td>0.224218</td>\n",
              "      <td>0.215862</td>\n",
              "      <td>0.132644</td>\n",
              "      <td>0.413182</td>\n",
              "      <td>0.344245</td>\n",
              "      <td>0.417941</td>\n",
              "      <td>0.245704</td>\n",
              "      <td>0.766766</td>\n",
              "      <td>0.807249</td>\n",
              "      <td>0.255782</td>\n",
              "      <td>0.790324</td>\n",
              "      <td>0.405397</td>\n",
              "      <td>0.599961</td>\n",
              "      <td>0.396832</td>\n",
              "      <td>0.672797</td>\n",
              "      <td>0.481298</td>\n",
              "      <td>0.254121</td>\n",
              "      <td>0.665085</td>\n",
              "      <td>0.207059</td>\n",
              "      <td>0.482732</td>\n",
              "      <td>0.463733</td>\n",
              "      <td>0.642630</td>\n",
              "      <td>0.520454</td>\n",
              "      <td>0.597138</td>\n",
              "      <td>0.440166</td>\n",
              "      <td>0.183721</td>\n",
              "      <td>0.500046</td>\n",
              "      <td>0.583028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>0.158653</td>\n",
              "      <td>0.504709</td>\n",
              "      <td>0.144445</td>\n",
              "      <td>0.441195</td>\n",
              "      <td>0.400698</td>\n",
              "      <td>0.385048</td>\n",
              "      <td>0.309333</td>\n",
              "      <td>0.202360</td>\n",
              "      <td>0.477538</td>\n",
              "      <td>0.474442</td>\n",
              "      <td>0.319211</td>\n",
              "      <td>0.326405</td>\n",
              "      <td>0.567261</td>\n",
              "      <td>0.623103</td>\n",
              "      <td>0.367338</td>\n",
              "      <td>0.267300</td>\n",
              "      <td>0.269656</td>\n",
              "      <td>0.605744</td>\n",
              "      <td>0.103580</td>\n",
              "      <td>0.312531</td>\n",
              "      <td>0.776485</td>\n",
              "      <td>0.202981</td>\n",
              "      <td>0.391037</td>\n",
              "      <td>0.160753</td>\n",
              "      <td>0.190403</td>\n",
              "      <td>0.488689</td>\n",
              "      <td>0.099460</td>\n",
              "      <td>0.056721</td>\n",
              "      <td>0.167374</td>\n",
              "      <td>0.703863</td>\n",
              "      <td>0.359446</td>\n",
              "      <td>0.400690</td>\n",
              "      <td>0.423428</td>\n",
              "      <td>0.471520</td>\n",
              "      <td>0.744525</td>\n",
              "      <td>0.650958</td>\n",
              "      <td>0.349274</td>\n",
              "      <td>0.351849</td>\n",
              "      <td>0.095035</td>\n",
              "      <td>0.525799</td>\n",
              "      <td>0.476887</td>\n",
              "      <td>0.311735</td>\n",
              "      <td>0.356889</td>\n",
              "      <td>0.837504</td>\n",
              "      <td>0.674515</td>\n",
              "      <td>0.174169</td>\n",
              "      <td>0.667679</td>\n",
              "      <td>0.501315</td>\n",
              "      <td>0.461384</td>\n",
              "      <td>0.291429</td>\n",
              "      <td>0.563620</td>\n",
              "      <td>0.592649</td>\n",
              "      <td>0.176090</td>\n",
              "      <td>0.750653</td>\n",
              "      <td>0.333158</td>\n",
              "      <td>0.370166</td>\n",
              "      <td>0.569408</td>\n",
              "      <td>0.484440</td>\n",
              "      <td>0.404574</td>\n",
              "      <td>0.494143</td>\n",
              "      <td>0.558071</td>\n",
              "      <td>0.302848</td>\n",
              "      <td>0.615317</td>\n",
              "      <td>0.684000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>0.296261</td>\n",
              "      <td>0.267619</td>\n",
              "      <td>0.323642</td>\n",
              "      <td>0.706469</td>\n",
              "      <td>0.647754</td>\n",
              "      <td>0.651406</td>\n",
              "      <td>0.524379</td>\n",
              "      <td>0.436216</td>\n",
              "      <td>0.749786</td>\n",
              "      <td>0.745988</td>\n",
              "      <td>0.547241</td>\n",
              "      <td>0.126965</td>\n",
              "      <td>0.317635</td>\n",
              "      <td>0.815240</td>\n",
              "      <td>0.608684</td>\n",
              "      <td>0.526574</td>\n",
              "      <td>0.092209</td>\n",
              "      <td>0.814227</td>\n",
              "      <td>0.177874</td>\n",
              "      <td>0.526256</td>\n",
              "      <td>0.574698</td>\n",
              "      <td>0.370376</td>\n",
              "      <td>0.670440</td>\n",
              "      <td>0.325047</td>\n",
              "      <td>0.400335</td>\n",
              "      <td>0.275451</td>\n",
              "      <td>0.244392</td>\n",
              "      <td>0.172040</td>\n",
              "      <td>0.377895</td>\n",
              "      <td>0.423196</td>\n",
              "      <td>0.532490</td>\n",
              "      <td>0.187990</td>\n",
              "      <td>0.181264</td>\n",
              "      <td>0.217310</td>\n",
              "      <td>0.480678</td>\n",
              "      <td>0.440746</td>\n",
              "      <td>0.131473</td>\n",
              "      <td>0.114153</td>\n",
              "      <td>0.191104</td>\n",
              "      <td>0.300818</td>\n",
              "      <td>0.222380</td>\n",
              "      <td>0.532968</td>\n",
              "      <td>0.164333</td>\n",
              "      <td>0.648477</td>\n",
              "      <td>0.895984</td>\n",
              "      <td>0.372280</td>\n",
              "      <td>0.881928</td>\n",
              "      <td>0.318042</td>\n",
              "      <td>0.730885</td>\n",
              "      <td>0.536975</td>\n",
              "      <td>0.753024</td>\n",
              "      <td>0.360409</td>\n",
              "      <td>0.350078</td>\n",
              "      <td>0.546207</td>\n",
              "      <td>0.119717</td>\n",
              "      <td>0.612890</td>\n",
              "      <td>0.331881</td>\n",
              "      <td>0.795842</td>\n",
              "      <td>0.621357</td>\n",
              "      <td>0.692510</td>\n",
              "      <td>0.325104</td>\n",
              "      <td>0.094144</td>\n",
              "      <td>0.373276</td>\n",
              "      <td>0.472433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>0.152026</td>\n",
              "      <td>0.514523</td>\n",
              "      <td>0.140539</td>\n",
              "      <td>0.434580</td>\n",
              "      <td>0.397319</td>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.307580</td>\n",
              "      <td>0.194721</td>\n",
              "      <td>0.467991</td>\n",
              "      <td>0.466925</td>\n",
              "      <td>0.312990</td>\n",
              "      <td>0.335456</td>\n",
              "      <td>0.571783</td>\n",
              "      <td>0.618706</td>\n",
              "      <td>0.353984</td>\n",
              "      <td>0.258329</td>\n",
              "      <td>0.273032</td>\n",
              "      <td>0.589136</td>\n",
              "      <td>0.101599</td>\n",
              "      <td>0.308522</td>\n",
              "      <td>0.791185</td>\n",
              "      <td>0.201823</td>\n",
              "      <td>0.376040</td>\n",
              "      <td>0.158427</td>\n",
              "      <td>0.185987</td>\n",
              "      <td>0.491544</td>\n",
              "      <td>0.095287</td>\n",
              "      <td>0.053654</td>\n",
              "      <td>0.160374</td>\n",
              "      <td>0.711324</td>\n",
              "      <td>0.352132</td>\n",
              "      <td>0.415817</td>\n",
              "      <td>0.427658</td>\n",
              "      <td>0.491670</td>\n",
              "      <td>0.756640</td>\n",
              "      <td>0.664033</td>\n",
              "      <td>0.357692</td>\n",
              "      <td>0.359389</td>\n",
              "      <td>0.091852</td>\n",
              "      <td>0.536450</td>\n",
              "      <td>0.475849</td>\n",
              "      <td>0.305536</td>\n",
              "      <td>0.362161</td>\n",
              "      <td>0.841512</td>\n",
              "      <td>0.665306</td>\n",
              "      <td>0.170202</td>\n",
              "      <td>0.654551</td>\n",
              "      <td>0.516120</td>\n",
              "      <td>0.453711</td>\n",
              "      <td>0.284048</td>\n",
              "      <td>0.561934</td>\n",
              "      <td>0.608478</td>\n",
              "      <td>0.171722</td>\n",
              "      <td>0.759622</td>\n",
              "      <td>0.334162</td>\n",
              "      <td>0.361943</td>\n",
              "      <td>0.588998</td>\n",
              "      <td>0.474480</td>\n",
              "      <td>0.400631</td>\n",
              "      <td>0.491232</td>\n",
              "      <td>0.561851</td>\n",
              "      <td>0.313718</td>\n",
              "      <td>0.620295</td>\n",
              "      <td>0.692292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>0.265334</td>\n",
              "      <td>0.303087</td>\n",
              "      <td>0.283004</td>\n",
              "      <td>0.670355</td>\n",
              "      <td>0.614989</td>\n",
              "      <td>0.609248</td>\n",
              "      <td>0.498748</td>\n",
              "      <td>0.380983</td>\n",
              "      <td>0.708901</td>\n",
              "      <td>0.711180</td>\n",
              "      <td>0.511516</td>\n",
              "      <td>0.149040</td>\n",
              "      <td>0.355224</td>\n",
              "      <td>0.796563</td>\n",
              "      <td>0.564177</td>\n",
              "      <td>0.474366</td>\n",
              "      <td>0.106317</td>\n",
              "      <td>0.791791</td>\n",
              "      <td>0.166972</td>\n",
              "      <td>0.500402</td>\n",
              "      <td>0.622424</td>\n",
              "      <td>0.343209</td>\n",
              "      <td>0.624781</td>\n",
              "      <td>0.293880</td>\n",
              "      <td>0.362891</td>\n",
              "      <td>0.298774</td>\n",
              "      <td>0.206581</td>\n",
              "      <td>0.143118</td>\n",
              "      <td>0.330789</td>\n",
              "      <td>0.475200</td>\n",
              "      <td>0.516268</td>\n",
              "      <td>0.218119</td>\n",
              "      <td>0.207351</td>\n",
              "      <td>0.256238</td>\n",
              "      <td>0.535020</td>\n",
              "      <td>0.473743</td>\n",
              "      <td>0.156280</td>\n",
              "      <td>0.136326</td>\n",
              "      <td>0.167981</td>\n",
              "      <td>0.330530</td>\n",
              "      <td>0.250491</td>\n",
              "      <td>0.497832</td>\n",
              "      <td>0.186196</td>\n",
              "      <td>0.692587</td>\n",
              "      <td>0.875573</td>\n",
              "      <td>0.336302</td>\n",
              "      <td>0.858868</td>\n",
              "      <td>0.347062</td>\n",
              "      <td>0.694364</td>\n",
              "      <td>0.490043</td>\n",
              "      <td>0.732245</td>\n",
              "      <td>0.401048</td>\n",
              "      <td>0.318632</td>\n",
              "      <td>0.586471</td>\n",
              "      <td>0.138987</td>\n",
              "      <td>0.570242</td>\n",
              "      <td>0.376153</td>\n",
              "      <td>0.758523</td>\n",
              "      <td>0.590132</td>\n",
              "      <td>0.660956</td>\n",
              "      <td>0.357540</td>\n",
              "      <td>0.116510</td>\n",
              "      <td>0.408500</td>\n",
              "      <td>0.508226</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>460592 rows  64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2  ...        61        62        63\n",
              "0    0.231430  0.352931  0.232025  ...  0.153995  0.469210  0.563165\n",
              "1    0.285400  0.280855  0.309056  ...  0.105349  0.391168  0.490527\n",
              "2    0.259602  0.315595  0.275291  ...  0.127841  0.427011  0.523648\n",
              "3    0.135609  0.568508  0.123433  ...  0.376007  0.665616  0.731804\n",
              "4    0.256028  0.319747  0.262084  ...  0.131711  0.437430  0.526776\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "587  0.216491  0.381766  0.210946  ...  0.183721  0.500046  0.583028\n",
              "588  0.158653  0.504709  0.144445  ...  0.302848  0.615317  0.684000\n",
              "589  0.296261  0.267619  0.323642  ...  0.094144  0.373276  0.472433\n",
              "590  0.152026  0.514523  0.140539  ...  0.313718  0.620295  0.692292\n",
              "591  0.265334  0.303087  0.283004  ...  0.116510  0.408500  0.508226\n",
              "\n",
              "[460592 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubUcPhs66mU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e1a59f4d-901d-4f02-a963-9a212bdb913b"
      },
      "source": [
        "df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>198526</th>\n",
              "      <td>0</td>\n",
              "      <td>well they aren that similar so there isn reall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484469</th>\n",
              "      <td>0</td>\n",
              "      <td>their are universities in canada as well though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266858</th>\n",
              "      <td>0</td>\n",
              "      <td>welcome to japan where the game devs wear lab ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126334</th>\n",
              "      <td>1</td>\n",
              "      <td>nah then people would have to actually get on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131105</th>\n",
              "      <td>1</td>\n",
              "      <td>bizarre he still performing when he already le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465015</th>\n",
              "      <td>1</td>\n",
              "      <td>hah do not come here and tell fables of a long...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28675</th>\n",
              "      <td>1</td>\n",
              "      <td>another ominous sign that global warming is re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528212</th>\n",
              "      <td>1</td>\n",
              "      <td>should i explain end tags or should you look t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43258</th>\n",
              "      <td>1</td>\n",
              "      <td>because it means you would have settled for le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70611</th>\n",
              "      <td>0</td>\n",
              "      <td>i turn screen shake on if there was a walks th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>460592 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        label                                            comment\n",
              "198526      0  well they aren that similar so there isn reall...\n",
              "484469      0    their are universities in canada as well though\n",
              "266858      0  welcome to japan where the game devs wear lab ...\n",
              "126334      1  nah then people would have to actually get on ...\n",
              "131105      1  bizarre he still performing when he already le...\n",
              "...       ...                                                ...\n",
              "465015      1  hah do not come here and tell fables of a long...\n",
              "28675       1  another ominous sign that global warming is re...\n",
              "528212      1  should i explain end tags or should you look t...\n",
              "43258       1  because it means you would have settled for le...\n",
              "70611       0  i turn screen shake on if there was a walks th...\n",
              "\n",
              "[460592 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmjgkeQrSmU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NDF.to_csv('/content/drive/My Drive/sarcastic_comments_train_extracted.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0o7Z6w0Ujtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.label.to_csv('/content/drive/My Drive/sarcastic_comments_train_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}